# 🚀 온디바이스 AI 기반 표정·수어 인식 앱
🧑‍💻 멤버 소개

202002529 이어진  
202202556 김도현  
202202593 박채연

📌 프로젝트 소개

이 프로젝트는 온디바이스 AI 기술을 활용하여 수어(손 제스처)와 표정을 실시간으로 인식하고, 이를 한국어 텍스트로 번역하는 모바일 애플리케이션 개발을 목표로 합니다.  
청각 장애인과 비장애인 간의 원활한 소통을 지원하며, 오프라인 환경에서도 동작 가능한 경량화된 AI 모델을 통해 접근성과 효율성을 극대화합니다.

주요 기능은 수어 동작과 표정을 분석하여 의미를 텍스트로 변환하고, 번역 결과를 화면에 표시하거나 다른 사용자와 공유하는 것입니다.  
이 프로젝트는 MediaPipe, 그리고 딥러닝 기반의 AI 알고리즘을 활용하여 높은 정확도와 실시간 처리를 구현합니다.

🎯 프로젝트 목표

실시간 수어 및 표정 인식: 사용자의 손 제스처와 표정을 카메라로 캡처하여 실시간으로 분석.  
텍스트 번역: 인식된 수어를 한국어 텍스트로 변환하고, 필요 시 영어로 추가 번역.  
온디바이스 최적화: 클라우드 의존성을 최소화하여 오프라인 환경에서도 안정적으로 동작.  
사용자 친화적 UI/UX: 직관적인 인터페이스로 모든 사용자가 쉽게 접근 가능.  

## 활동 기록  

| 주차  | 활동 개요               | 발표 URL | 깃 PR 링크 |
|------|----------------------|---------|------------------|
| 1주차 | 디자인 개요서 작성 | [유튜브 링크](https://youtu.be/k6VoF2thGbg) | [PR 링크](https://github.com/CD03-01/mobile-ai-service/pull/1) |
| 2주차 | 문제점 목록 작성 | [유튜브 링크](https://youtu.be/iseAybqoh64) | [PR 링크](https://github.com/CD03-01/mobile-ai-service/pull/2) |
| 3주차 | 브레인스토밍 결과 작성 | [유튜브 링크](https://youtu.be/8QuSFgxh-No) | [PR 링크](https://github.com/CD03-01/mobile-ai-service/pull/4) |
| 4주차 | 문제정의서 작성 | [유튜브 링크](https://www.youtube.com/watch?v=qooUvmYUQIk) | [PR 링크](https://github.com/CD03-01/mobile-ai-service/pull/6) |
| 5-6주차 | 유스케이스 명세서 작성 | [유튜브 링크](https://www.youtube.com/watch?v=jPpd5OYzP-Q) | [PR 링크](https://github.com/CD03-01/mobile-ai-service/pull/7) |
| 7-8주차 | 시퀀스 다이어그램 작성 | [유튜브 링크](https://www.youtube.com/watch?v=7SPE0kdX9PE) | [PR 링크](https://github.com/CD03-01/mobile-ai-service/pull/8) |
| 9-10주차 | 테스트 계획서 작성 | [유튜브 링크] | [PR 링크] |
| 11-12주차 | 테스트케이스 설계서 작성 | [유튜브 링크] | [PR 링크] |
| 13-14주차 | 테스트 결과 보고서 작성 | [유튜브 링크] | [PR 링크] |
